# üìâ ChurnInsight ‚Äì Data Science (Hackathon)

## 1. Descripci√≥n del desaf√≠o

El desaf√≠o **ChurnInsight** consiste en desarrollar una soluci√≥n de *Data Science* capaz de **predecir si un cliente es propenso a cancelar un servicio (churn)**.

En el contexto del hackathon, el proyecto se divide en dos grandes componentes:
- **Equipo de Data Science**: desarrollo del modelo predictivo de churn.
- **Equipo de Back-end**: construcci√≥n de una API que expone la predicci√≥n del modelo a otros sistemas.

Este repositorio documenta **exclusivamente el trabajo del equipo de Data Science**, desde la preparaci√≥n de los datos hasta la optimizaci√≥n y serializaci√≥n del modelo.

---

## 2. Problema de negocio (visi√≥n no t√©cnica)

Las empresas que operan bajo modelos de suscripci√≥n o contratos recurrentes enfrentan constantemente el problema de la cancelaci√≥n de clientes. Retener clientes existentes es significativamente m√°s econ√≥mico que adquirir nuevos.

La empresa desea **anticiparse a la cancelaci√≥n**, identificando clientes con alto riesgo de churn para:
- Priorizar acciones de retenci√≥n.
- Ofrecer beneficios personalizados.
- Actuar de forma preventiva desde soporte o marketing.
- Medir el impacto de estas acciones a lo largo del tiempo.

---

## 3. Validaci√≥n de mercado

La predicci√≥n de churn es una de las aplicaciones m√°s comunes y valiosas de la ciencia de datos en negocios modernos.

Sectores como:
- Telecomunicaciones  
- Bancos digitales y fintech  
- Plataformas de streaming  
- Gimnasios  
- Software SaaS  

utilizan modelos de churn para:
- Reducir p√©rdidas financieras.
- Comprender patrones de comportamiento.
- Incrementar el *lifetime value* del cliente.

Incluso modelos simples generan valor al permitir enfocar esfuerzos donde el riesgo es mayor.

---

## 4. Objetivo del equipo de Data Science

Desarrollar un **modelo de clasificaci√≥n binaria** capaz de predecir si un cliente:
- **Va a cancelar**
- **Va a continuar**

a partir de informaci√≥n hist√≥rica de uso, contrato y comportamiento, entregando adem√°s una **probabilidad asociada a la predicci√≥n**.

---

## 5. Dataset

El dataset utilizado contiene informaci√≥n de clientes, incluyendo variables como:
- Tiempo de contrato
- Uso del servicio
- Historial de pagos
- Tipo de plan
- Variables demogr√°ficas y de comportamiento

La variable objetivo es binaria e indica si el cliente abandon√≥ el servicio (*churn*).

El volumen de datos fue controlado considerando las limitaciones del **Free Tier de OCI**.

---

## 6. Metodolog√≠a y estructura del proyecto

El proyecto se desarroll√≥ siguiendo un pipeline cl√°sico de *Machine Learning*, dividido en tres fases principales, cada una documentada en un notebook independiente.

```
üìÅ notebooks/
 ‚îú‚îÄ‚îÄ 01_ETL_hackathon.ipynb
 ‚îú‚îÄ‚îÄ 02_Modelado_hackathon.ipynb
 ‚îî‚îÄ‚îÄ 03_Optimizacion_modelo_hackathon.ipynb
```

---

## 7. Fase 1 ‚Äì ETL y preparaci√≥n de datos  
**Notebook:** `01_ETL_hackathon.ipynb`

En esta etapa se realiz√≥ el proceso de *Extract, Transform & Load (ETL)* para dejar los datos listos para el entrenamiento del modelo.

### Actividades principales:
- Exploraci√≥n inicial del dataset (EDA).
- An√°lisis de tipos de datos y valores faltantes.
- Limpieza y depuraci√≥n.
- Selecci√≥n de variables relevantes.
- Preparaci√≥n del dataset final para modelado.

**Resultado:**  
Un dataset limpio, consistente y adecuado para algoritmos de *Machine Learning*.

---

## 8. Fase 2 ‚Äì Modelado predictivo  
**Notebook:** `02_Modelado_hackathon.ipynb`

En esta fase se entrenaron distintos modelos de clasificaci√≥n para establecer una l√≠nea base de desempe√±o.

### Actividades principales:
- Separaci√≥n de datos en entrenamiento y prueba.
- Entrenamiento de modelos supervisados.
- Comparaci√≥n de desempe√±o entre modelos.
- Evaluaci√≥n considerando el desbalance de clases.

### M√©tricas utilizadas:
- Accuracy  
- Precision  
- Recall  
- F1-score  
- ROC-AUC  

**Resultado:**  
Se identificaron modelos con mejor capacidad predictiva y potencial de mejora.

---

## 9. Fase 3 ‚Äì Optimizaci√≥n del modelo  
**Notebook:** `03_Optimizacion_modelo_hackathon.ipynb`

En la fase final se busc√≥ mejorar el desempe√±o del modelo seleccionado.

### Actividades principales:
- Ajuste de hiperpar√°metros.
- Comparaci√≥n entre modelos optimizados y no optimizados.
- An√°lisis del impacto de la optimizaci√≥n en m√©tricas clave.

**Resultado:**  
Modelo final optimizado, con mejor equilibrio entre rendimiento y capacidad de generalizaci√≥n.

---

## 10. Serializaci√≥n del modelo

El modelo final y su pipeline fueron **serializados** para permitir su uso fuera del notebook, facilitando la integraci√≥n con el equipo de Back-end.

Herramientas utilizadas:
- `joblib`
- `pickle`

El modelo puede ser cargado por la API para realizar predicciones en tiempo real.

---

## 11. Alcance del MVP (Data Science)

- Clasificaci√≥n binaria de churn.
- Predicci√≥n acompa√±ada de probabilidad.
- Modelo reproducible y exportable.
- Dataset peque√±o y controlado.
- M√©tricas claras y justificadas.

---

## 12. Stack tecnol√≥gico

- **Lenguaje:** Python  
- **An√°lisis y modelado:** Pandas, NumPy, scikit-learn  
- **Entorno:** Jupyter Notebook / Google Colab  
- **Serializaci√≥n:** joblib / pickle  
- **Control de versiones:** Git / GitHub  

---

## 13. Notas finales

Este proyecto fue desarrollado dentro de un **hackathon**, priorizando:
- Claridad metodol√≥gica.
- Buenas pr√°cticas de Data Science.
- Aplicabilidad real al negocio.
- Facilidad de integraci√≥n con sistemas externos.

El trabajo del equipo de Back-end se documenta en un repositorio independiente.
